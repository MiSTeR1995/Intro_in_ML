{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e189544-4462-485c-a319-7fd448e051b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Подготовка окружения: импорты, устройство, конфиг.\n",
    "# Этот блок ничего не скачивает и не обучает — только настраивает.\n",
    "# ============================================================\n",
    "# --- стандартные библиотеки ---\n",
    "import os, math, random, time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict\n",
    "import pandas as pd # для таблиц\n",
    "import matplotlib.pyplot as plt  # для графиков\n",
    "import numpy as np\n",
    "# --- PyTorch ядро ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Hugging Face Datasets: для загрузки готовых датасетов (изображения, тексты и др.)\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TorchVision: стандартные преобразования изображений (resize, crop, normalize и т.д.)\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "# -----------------------------\n",
    "# Функция для воспроизводимости\n",
    "# -----------------------------\n",
    "# ========== ВОСПРОИЗВОДИМОСТЬ ==========\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"Фиксирует ГСЧ для повторяемых результатов (Python/NumPy/PyTorch).\"\"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# Определение устройства (CPU/GPU)\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Детерминизм на CUDA (чуть медленнее, но стабильнее)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # При необходимости:\n",
    "    # torch.use_deterministic_algorithms(True)  \n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Конфигурация эксперимента\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Имя датасета в Hugging Face Datasets; 'beans' — небольшой датасет изображений (3 класса)\n",
    "    dataset_name: str = \"beans\"            # str: идентификатор датасета в HF\n",
    "\n",
    "    # Целевой размер стороны изображения после ресайза (квадрат до image_size x image_size)\n",
    "    image_size: int = 128                  # int: компромисс скорость/качество; 128 достаточно для быстрых итераций\n",
    "\n",
    "    # Размер мини-батча: влияет на стабильность градиента и скорость итераций\n",
    "    batch_size: int = 16                   # int: 32–128 обычно стабильны на небольших моделях/датасетах\n",
    "\n",
    "    # Количество воркеров для DataLoader (параллельная загрузка данных)\n",
    "    num_workers: int = 0                   # int: 0 для Windows/ноутбуков без многопроцессной загрузки; 2–4 часто достаточно\n",
    "\n",
    "    epochs: int = 10                        # Количество эпох обучения (проходов по train-части датасета)\n",
    "\n",
    "    # Базовая скорость обучения (learning rate) — ключевой гиперпараметр оптимизации\n",
    "    lr: float = 1e-2                       # float: стартовое значение; оптимальный LR зависит от оптимизатора и модели\n",
    "\n",
    "    # Коэффициент L2-регуляризации (weight decay): для AdamW используется как «правильный» распад весов\n",
    "    weight_decay: float = 0.0              # float: >=0; напр. 0.01 для AdamW\n",
    "\n",
    "    # Использовать ли смешанную точность (AMP) при наличии CUDA (ускорение + экономия памяти)\n",
    "    mixed_precision: bool = True           # bool: True — включать torch.autocast при обучении на GPU\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13541de1-da65-4496-82eb-874bb232414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Загрузка датасета 'beans' с кешированием в ./data/hf_cache\n",
    "# и формирование одной аккуратной таблицы со сводной информацией.\n",
    "# ============================================================\n",
    "\n",
    "set_seed(42)\n",
    "# 1) Подготовка локальной папки для кеша\n",
    "os.makedirs(\"./data/hf_cache\", exist_ok=True)\n",
    "\n",
    "# 2) Загрузка датасета с локальным кешированием\n",
    "ds = load_dataset(cfg.dataset_name, cache_dir=\"./data/hf_cache\")\n",
    "\n",
    "# 3) Проверка наличия ожидаемых сплитов\n",
    "expected_splits = {\"train\", \"validation\", \"test\"}\n",
    "actual_splits = set(ds.keys())\n",
    "missing = expected_splits - actual_splits\n",
    "assert not missing, f\"Отсутствуют сплиты: {missing}. Доступные: {actual_splits}\"\n",
    "\n",
    "# 4) Получение ссылок на сплиты\n",
    "train_ds, val_ds, test_ds = ds[\"train\"], ds[\"validation\"], ds[\"test\"]\n",
    "\n",
    "# 5) Информация о классах (человеко-читаемые имена)\n",
    "label_names = train_ds.features[\"labels\"].names\n",
    "num_classes = len(label_names)\n",
    "\n",
    "# 6) Формирование одной таблицы: сплит + размер + число классов + список имён классов\n",
    "info_records = [\n",
    "    {\n",
    "        \"split\": split,\n",
    "        \"size\": len(ds[split]),\n",
    "        \"num_classes\": num_classes,\n",
    "        \"class_names\": \", \".join(label_names)\n",
    "    }\n",
    "    for split in sorted(ds.keys())\n",
    "]\n",
    "\n",
    "info_df = pd.DataFrame(info_records)\n",
    "\n",
    "# 7) Оформление таблицы Styler: шапка, выравнивание, форматирование\n",
    "styled_info = (\n",
    "    info_df.style\n",
    "    .set_caption(\"Сводная информация о датасете 'beans'\")\n",
    "    .format({\"size\": \"{:,}\"})\n",
    "    .hide(axis=\"index\")\n",
    "    .set_table_styles([\n",
    "        {\"selector\": \"caption\", \"props\": [(\"font-size\", \"16px\"), (\"font-weight\", \"bold\"), (\"text-align\", \"left\")]},\n",
    "        {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]},\n",
    "        {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\")]},\n",
    "    ])\n",
    ")\n",
    "\n",
    "display(styled_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25948634-da42-41b4-918f-4f6cc4a348c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Распределение классов по каждому сплиту\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd  # уже был в 2A; оставлено на случай отдельного исполнения ячейки\n",
    "\n",
    "def class_distribution(split_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Возвращает DataFrame с частотами и долями классов для указанного сплита.\n",
    "    Колонки: class_id, class_name, count, share\n",
    "    \"\"\"\n",
    "    labels = ds[split_name][\"labels\"]  # список int-меток\n",
    "    counts = pd.Series(labels).value_counts().sort_index()\n",
    "    df = pd.DataFrame({\n",
    "        \"class_id\": counts.index,\n",
    "        \"class_name\": [label_names[i] for i in counts.index],\n",
    "        \"count\": counts.values\n",
    "    })\n",
    "    df[\"share\"] = df[\"count\"] / df[\"count\"].sum()\n",
    "    return df\n",
    "set_seed(42)\n",
    "train_dist = class_distribution(\"train\")\n",
    "val_dist   = class_distribution(\"validation\")\n",
    "test_dist  = class_distribution(\"test\")\n",
    "\n",
    "def style_distribution(df: pd.DataFrame, title: str) -> pd.io.formats.style.Styler:\n",
    "    return (\n",
    "        df.style\n",
    "        .set_caption(title)\n",
    "        .format({\"count\": \"{:,}\", \"share\": \"{:.2%}\"})\n",
    "        .bar(subset=[\"share\"])  # визуальная полоса по долям\n",
    "        .hide(axis=\"index\")\n",
    "        .set_table_styles([\n",
    "            {\"selector\": \"caption\", \"props\": [(\"font-size\", \"16px\"), (\"font-weight\", \"bold\"), (\"text-align\", \"left\")]},\n",
    "            {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]},\n",
    "            {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\")]},\n",
    "        ])\n",
    "    )\n",
    "\n",
    "display(style_distribution(train_dist, \"Распределение классов — train\"))\n",
    "display(style_distribution(val_dist,   \"Распределение классов — validation\"))\n",
    "display(style_distribution(test_dist,  \"Распределение классов — test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701c918-e17e-4e89-9e5f-9d40d00b799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# для каждого класса три столбца (train/validation/test).\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Упорядочиваем по class_id, чтобы бары совпадали по позициям\n",
    "t = train_dist.sort_values(\"class_id\").reset_index(drop=True)\n",
    "v = val_dist.sort_values(\"class_id\").reset_index(drop=True)\n",
    "e = test_dist.sort_values(\"class_id\").reset_index(drop=True)\n",
    "\n",
    "x = np.arange(len(t))      # позиции классов\n",
    "w = 0.25                   # ширина одного столбца\n",
    "\n",
    "plt.figure(figsize=(8, 4.5))\n",
    "plt.bar(x - w, t[\"count\"], width=w, label=\"train\")\n",
    "plt.bar(x,     v[\"count\"], width=w, label=\"validation\")\n",
    "plt.bar(x + w, e[\"count\"], width=w, label=\"test\")\n",
    "\n",
    "plt.xticks(x, t[\"class_name\"], rotation=0)\n",
    "plt.title(\"Сравнение распределения классов по сплитам (count)\")\n",
    "plt.xlabel(\"Класс\")\n",
    "plt.ylabel(\"Количество\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326626f2-94d4-483d-a15d-e1c8c6cad0c1",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "Распределение классов в датасете *Beans* является **равномерным** (около 33 % на каждый класс).  \n",
    "Такое соотношение **исключает смещение модели** и обеспечивает **корректную оценку метрик качества** при обучении и сравнении оптимизаторов.  \n",
    "\n",
    "Классы:  \n",
    "- **angular_leaf_spot** — угловатая пятнистость листьев  \n",
    "- **bean_rust** — ржавчина фасоли  \n",
    "- **healthy** — здоровые листья\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7653e-933c-4992-aae6-5088604612f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Визуализация сетки примеров изображений.\n",
    "# Показывает n случайных образцов из указанного сплита.\n",
    "# ============================================================\n",
    "\n",
    "def show_image_grid(\n",
    "    split_name: str = \"train\",\n",
    "    n: int = 10,                 # количество изображений в сетке\n",
    "    cols: int = 5,               # число столбцов в сетке\n",
    "    seed: int = 42,              # для воспроизводимого выбора\n",
    "    title: str | None = None,    # заголовок фигуры\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Визуализирует случайную подборку изображений из сплита ds[split_name].\n",
    "    Подпись под каждым изображением — человеко-читаемое имя класса.\n",
    "    \"\"\"\n",
    "    assert split_name in ds, f\"Неизвестный сплит: {split_name}. Доступные: {list(ds.keys())}\"\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    # Выбор индексов\n",
    "    split = ds[split_name]\n",
    "    n = min(n, len(split))                    # защита от выхода за пределы\n",
    "    idxs = rng.sample(range(len(split)), n)   # случайные индексы без повторов\n",
    "\n",
    "    # Параметры сетки\n",
    "    rows = math.ceil(n / cols)\n",
    "    plt.figure(figsize=(cols * 2.5, rows * 2.5))  # масштабируем размер фигуры от сетки\n",
    "\n",
    "    for i, idx in enumerate(idxs, start=1):\n",
    "        example = split[idx]\n",
    "        img = example[\"image\"]                # PIL.Image.Image\n",
    "        label_id = example[\"labels\"]\n",
    "        label = label_names[label_id]\n",
    "\n",
    "        ax = plt.subplot(rows, cols, i)\n",
    "        ax.imshow(img)                        # изображения в beans RGB, без нормализации для просмотра\n",
    "        ax.set_title(label, fontsize=10)      # краткая подпись класса\n",
    "        ax.axis(\"off\")                        # скрыть оси для чистоты визуализации\n",
    "\n",
    "    if title is None:\n",
    "        title = f\"Примеры изображений — {split_name}\"\n",
    "    plt.suptitle(title, y=0.98, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Пример вызова: сетка из train-сплита\n",
    "show_image_grid(split_name=\"train\", n=10, cols=5, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab4a794-486b-4d9d-aa45-f6bfee904ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Блок 2C.2. Визуализация: по одному примеру на класс.\n",
    "# Удобно для быстрой проверки классов и их отличий.\n",
    "# ============================================================\n",
    "\n",
    "def show_one_per_class(\n",
    "    split_name: str = \"train\",\n",
    "    seed: int = 42,                   # для воспроизводимого выбора среди множества примеров класса\n",
    "    cols: int | None = None,          # число столбцов; по умолчанию = числу классов (в одну строку)\n",
    "    title: str | None = None,\n",
    ") -> None:\n",
    "    assert split_name in ds, f\"Неизвестный сплит: {split_name}. Доступные: {list(ds.keys())}\"\n",
    "    rng = random.Random(seed)\n",
    "    split = ds[split_name]\n",
    "\n",
    "    # Для каждого класса берём случайный индекс соответствующего примера\n",
    "    by_class = {i: [] for i in range(num_classes)}\n",
    "    for idx in range(len(split)):\n",
    "        lab = split[idx][\"labels\"]\n",
    "        if len(by_class[lab]) < 32:  # ограничиваем накопление для ускорения\n",
    "            by_class[lab].append(idx)\n",
    "\n",
    "    chosen = []\n",
    "    for c in range(num_classes):\n",
    "        assert len(by_class[c]) > 0, f\"В сплите {split_name} нет примеров класса {c} ({label_names[c]})\"\n",
    "        chosen.append(rng.choice(by_class[c]))\n",
    "\n",
    "    # Сетка: одна строка по умолчанию (или разбивка на несколько строк)\n",
    "    if cols is None:\n",
    "        cols = num_classes\n",
    "    rows = math.ceil(num_classes / cols)\n",
    "\n",
    "    plt.figure(figsize=(cols * 4, rows * 4))\n",
    "    for i, idx in enumerate(chosen, start=1):\n",
    "        ex = split[idx]\n",
    "        img = ex[\"image\"]\n",
    "        lab = ex[\"labels\"]\n",
    "        ax = plt.subplot(rows, cols, i)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{label_names[lab]}\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    if title is None:\n",
    "        title = f\"По одному примеру на класс — {split_name}\"\n",
    "    plt.suptitle(title, y=0.98, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Пример\n",
    "show_one_per_class(split_name=\"train\", seed=111, cols=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16b316-777c-4e26-9fca-6a6896ce2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Демонстрация простых преобразований (аугментация):\n",
    "#   1) Оригинал (как есть)\n",
    "#   2) Resize до cfg.image_size (качественная интерполяция LANCZOS)\n",
    "#   3) Resize + горизонтальный флип\n",
    "# Показ без сглаживания (interpolation=\"none\") для сравнения резкости.\n",
    "# ============================================================\n",
    "\n",
    "import torchvision.transforms.functional as TF \n",
    "set_seed(42)\n",
    "def preview_resize_flip(\n",
    "    split_name: str = \"train\",\n",
    "    n: int = 5,               # число строк (изображений) для показа\n",
    "    seed: int = 42,           # фиксируем выбор образцов\n",
    "    size: int | None = None,  # целевой размер стороны; по умолчанию cfg.image_size\n",
    ") -> None:\n",
    "    assert split_name in ds, f\"Неизвестный сплит: {split_name}. Доступные: {list(ds.keys())}\"\n",
    "    rng = random.Random(seed)\n",
    "    split = ds[split_name]\n",
    "    n = min(n, len(split))\n",
    "    if size is None:\n",
    "        size = cfg.image_size\n",
    "\n",
    "    # выбираем детерминированно n индексов\n",
    "    idxs = list(range(len(split)))\n",
    "    rng.shuffle(idxs)\n",
    "    idxs = idxs[:n]\n",
    "\n",
    "    cols = 3  # оригинал | ресайз | ресайз+флип\n",
    "    plt.figure(figsize=(cols * 3.2, n * 2.6))\n",
    "\n",
    "    for row, idx in enumerate(idxs):\n",
    "        ex = split[idx]\n",
    "        img_pil = ex[\"image\"]                  # PIL.Image\n",
    "        lab = label_names[ex[\"labels\"]]\n",
    "\n",
    "        # --- (1) Оригинал ---\n",
    "        ax = plt.subplot(n, cols, row * cols + 1)\n",
    "        ax.imshow(img_pil, interpolation=\"none\")  # никаких доп. сглаживаний\n",
    "        ax.set_title(f\"оригинал | {lab}\", fontsize=9)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # --- (2) Ресайз ---\n",
    "        img_resized = TF.resize(\n",
    "            img_pil,\n",
    "            size=[size, size],\n",
    "            interpolation=InterpolationMode.LANCZOS,  # качественный даунскейл\n",
    "            antialias=True\n",
    "        )\n",
    "        ax = plt.subplot(n, cols, row * cols + 2)\n",
    "        ax.imshow(img_resized, interpolation=\"none\")\n",
    "        ax.set_title(f\"ресайз {size}×{size}\", fontsize=9)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # --- (3) Ресайз + флип ---\n",
    "        img_flip = TF.hflip(img_resized)\n",
    "        ax = plt.subplot(n, cols, row * cols + 3)\n",
    "        ax.imshow(img_flip, interpolation=\"none\")\n",
    "        ax.set_title(f\"ресайз {size}×{size} + флип\", fontsize=9)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"Простые преобразования — {split_name}\", y=0.995, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Пример вызова:\n",
    "preview_resize_flip(split_name=\"train\", n=6, seed=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0542b22d-c1e1-4c30-a609-d9a60c975dee",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "На представленных примерах показаны базовые операции аугментации изображений в обучающей выборке:\n",
    "1. **Оригинал** — исходное изображение без изменений.  \n",
    "2. **Resize** — масштабирование до фиксированного размера `128×128` с использованием интерполяции *LANCZOS* для сохранения деталей.  \n",
    "3. **Resize + Flip** — масштабирование и горизонтальное отражение, что увеличивает вариативность данных.\n",
    "\n",
    "Такие преобразования повышают **обобщающую способность модели**, предотвращая переобучение и позволяя модели устойчивее распознавать объекты при изменении ориентации и масштаба.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631948f0-dca9-4022-8d9d-55b87d87de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Преобразования входных изображений.\n",
    "# Обучение: Resize до cfg.image_size + случайный горизонтальный флип + ToTensor.\n",
    "# Валидация/тест: только Resize + ToTensor.\n",
    "set_seed(42)\n",
    "# ------------------------------------------------------------\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((cfg.image_size, cfg.image_size), interpolation=InterpolationMode.BILINEAR, antialias=True),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ToTensor(),  \n",
    "])\n",
    "\n",
    "eval_transform = T.Compose([\n",
    "    T.Resize((cfg.image_size, cfg.image_size), interpolation=InterpolationMode.BILINEAR, antialias=True),\n",
    "    T.ToTensor(), \n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# преобразования \"на лету\" через set_transform.\n",
    "# set_transform передаёт на вход ЧАЩЕ ВСЕГО БАТЧ (dict со списками),\n",
    "# поэтому функция должна уметь обрабатывать и list, и одиночные объекты.\n",
    "# ------------------------------------------------------------\n",
    "def make_set_transform(pipeline: T.Compose):\n",
    "    def _apply(examples: dict) -> dict:\n",
    "        imgs = examples[\"image\"]\n",
    "        # Случай 1: батч (список PIL.Image)\n",
    "        if isinstance(imgs, list):\n",
    "            examples[\"image\"] = [pipeline(img) for img in imgs]  # -> список Tensor[C,H,W]\n",
    "        else:\n",
    "            # Случай 2: одиночный пример (PIL.Image)\n",
    "            examples[\"image\"] = pipeline(imgs)                    # -> Tensor[C,H,W]\n",
    "        return examples\n",
    "    return _apply\n",
    "\n",
    "train_ds.set_transform(make_set_transform(train_transform))  # аугментации только для train\n",
    "val_ds.set_transform(make_set_transform(eval_transform))    \n",
    "test_ds.set_transform(make_set_transform(eval_transform))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b6677-0197-4ff5-9d5f-783fa71378af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# collate_fn: принимает либо список примеров, либо уже \"батч-словарь\"\n",
    "# (что выдаёт HF при auto-collation). Возвращает (images, labels) тензоры.\n",
    "# ------------------------------------------------------------\n",
    "def collate_fn(batch):\n",
    "    # Случай A: HF уже вернул батч-словарь (колонки -> списки/тензоры)\n",
    "    if isinstance(batch, dict):\n",
    "        # 'image' после set_transform — либо список Tensor[C,H,W], либо уже Tensor[B,C,H,W]\n",
    "        imgs = batch[\"image\"]\n",
    "        if isinstance(imgs, list):\n",
    "            images = torch.stack(imgs, dim=0)  # [B,C,H,W]\n",
    "        else:\n",
    "            images = imgs                      # уже Tensor[B,C,H,W]\n",
    "        # 'labels' — список ints или Tensor[B]\n",
    "        labs = batch[\"labels\"]\n",
    "        labels = torch.as_tensor(labs, dtype=torch.long)\n",
    "        return images, labels\n",
    "\n",
    "    # Случай B: обычный список примеров (list of dicts)\n",
    "    images = torch.stack([b[\"image\"] for b in batch], dim=0)              # [B,C,H,W]\n",
    "    labels = torch.tensor([b[\"labels\"] for b in batch], dtype=torch.long) # [B]\n",
    "    return images, labels\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DataLoader'ы\n",
    "# ------------------------------------------------------------\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,  num_workers=0, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=cfg.batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=cfg.batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a370d10-aaa1-4e99-a90f-f048b779edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Контрольная проверка: формы, типы и диапазон значений первого батча из train_loader.\n",
    "# ------------------------------------------------------------\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"images:\", xb.shape, xb.dtype, f\"value range ~ [{xb.min():.3f}, {xb.max():.3f}]\")\n",
    "print(\"labels:\", yb.shape, yb.dtype, \"classes:\", sorted(set(yb.tolist())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff31601-711e-4b5f-8d74-0983ddb40f82",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "Контрольная проверка подтверждает корректность подготовки данных:  \n",
    "- **Форма изображений:** `[16, 3, 128, 128]` соответствует батчу из 64 цветных изображений (3 канала RGB, размер 128×128).  \n",
    "- **Тип данных:** `torch.float32`, диапазон значений `[0.0, 1.0]` — нормализованный тензор после преобразования `ToTensor()`.  \n",
    "- **Метки:** размер `[16]`, тип `torch.int64`, классы `[0, 1, 2]` — соответствуют трём категориям датасета (*угловатая пятнистость*, *ржавчина фасоли*, *здоровые листья*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03afbe3-60bb-4691-85aa-43fda1572395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Определение свёрточной модели для классификации изображений.\n",
    "# ------------------------------------------------------------\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        # Блок извлечения признаков: Conv-ReLU-MaxPool × 2\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # [B,16,H,W]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             # [B,16,H/2,W/2]\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # [B,32,H/2,W/2]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             # [B,32,H/4,W/4]\n",
    "        )\n",
    "        # Классификатор: сглаживание -> два полносвязных слоя\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                                # [B, 32*(H/4)*(W/4)]\n",
    "            nn.Linear(32 * (cfg.image_size // 4) * (cfg.image_size // 4), 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "set_seed(42)\n",
    "model = SimpleCNN(num_classes=len(label_names)).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd18286b-d605-4446-a372-d3c5d45a6f40",
   "metadata": {},
   "source": [
    "### Подробное описание модели `SimpleCNN`\n",
    "\n",
    "Модель `SimpleCNN` реализует базовую архитектуру **свёрточной нейронной сети (CNN)**, предназначенной для классификации изображений листьев фасоли по трём категориям:\n",
    "- *angular_leaf_spot* — угловатая пятнистость листьев,  \n",
    "- *bean_rust* — ржавчина фасоли,  \n",
    "- *healthy* — здоровые листья.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Блок `features` — извлечение признаков**\n",
    "Этот блок отвечает за выделение ключевых визуальных особенностей изображений: контуров, текстур, цветовых и структурных паттернов.  \n",
    "\n",
    "- **`Conv2d(3, 16, kernel_size=3, stride=1, padding=1)`**  \n",
    "  Первый свёрточный слой принимает RGB-изображение (3 канала) и обучается выделять базовые признаки — края, пятна, прожилки на листьях.  \n",
    "  Параметры ядра `3×3` и `padding=1` сохраняют пространственный размер.  \n",
    "\n",
    "- **`ReLU()`**  \n",
    "  Вводит нелинейность и обнуляет отрицательные значения, позволяя сети обучаться сложным зависимостям.  \n",
    "\n",
    "- **`MaxPool2d(2)`**  \n",
    "  Уменьшает размер изображения в 2 раза, выделяя наиболее выраженные признаки и снижая вычислительную нагрузку.  \n",
    "\n",
    "- **Второй блок `Conv2d(16, 32, ...) + ReLU + MaxPool2d(2)`**  \n",
    "  Повторение свёртки с увеличением числа каналов до 32 позволяет выявлять более сложные комбинации признаков — например, характерное распределение пятен болезни на листе.  \n",
    "\n",
    "После двух уровней свёрток и подвыборок размер признаковой карты уменьшается в 4 раза по каждой оси:  \n",
    "`128×128 → 64×64 → 32×32`, а глубина растёт до 32 каналов.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Блок `classifier` — принятие решения**\n",
    "После извлечения признаков тензор преобразуется в вектор и проходит через полносвязную часть модели.\n",
    "\n",
    "- **`Flatten()`**  \n",
    "  Превращает многомерный тензор признаков `[32, 32, 32]` в одномерный вектор длиной 32×32×32 = 32768 для подачи в линейный слой.  \n",
    "\n",
    "- **`Linear(32768, 16)` + `ReLU()`**  \n",
    "  Первый полносвязный слой учится находить абстрактные сочетания признаков, которые помогают различать типы заболеваний.  \n",
    "  Например, он может различать мелкие равномерные пятна (*bean_rust*) и крупные угловатые поражения (*angular_leaf_spot*).\n",
    "\n",
    "- **`Linear(16, 3)`**  \n",
    "  Финальный слой выдаёт логиты для трёх классов. После применения `Softmax` на выходе получаем вероятности принадлежности изображения к каждому классу.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Общая структура**\n",
    "Модель имеет **два уровня свёртки и два уровня классификации**, что делает её лёгкой, интерпретируемой и быстрой для обучения.  \n",
    "Она идеально подходит для учебных демонстраций, так как:\n",
    "- позволяет визуализировать влияние оптимизаторов (SGD, Adam и др.) на скорость сходимости;\n",
    "- даёт наглядное понимание, как CNN извлекает и обобщает признаки изображений.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ceaca-843d-41e4-91a5-fd9b7b2e5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Настройка функции потерь и оптимизатора.\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=cfg.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e53b9-67b3-4677-a2f6-1d2b400bc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Тестовый проход одной батч-выборки через модель.\n",
    "# ------------------------------------------------------------\n",
    "xb, yb = xb.to(device), yb.to(device)\n",
    "logits = model(xb)\n",
    "print(\"logits:\", logits.shape)        # [B, num_classes]\n",
    "print(\"loss:\", criterion(logits, yb).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60facf6-5c76-466a-bc09-8ea0b27e6303",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "Проведена проверка прямого прохода батча через модель:\n",
    "\n",
    "- **Функция потерь:** `CrossEntropyLoss()` — стандартная для многоклассовой классификации; сравнивает распределение логитов модели с правильными метками классов.  \n",
    "- **Оптимизатор:** `SGD` с начальным шагом обучения `lr = 1e-3`. На следующих этапах этот оптимизатор будет заменяться другими (Momentum, Adam, RMSProp) для сравнения эффективности.\n",
    "\n",
    "Результаты тестового прохода:\n",
    "- Размер логитов: `[16, 3]` — для каждого из 16 изображений предсказаны 3 значения (по числу классов).  \n",
    "- Потеря (`loss ≈ 1.13`) — начальное значение ошибки до обучения, что соответствует случайным прогнозам модели.\n",
    "\n",
    "Таким образом, прямой проход и вычисление функции потерь выполняются корректно; модель готова к этапу обучения и анализу поведения различных оптимизаторов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b47c6e-bb51-479c-95e9-95c11b1f3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Цикл для сравнения оптимизаторов.\n",
    "# Предпосылки:\n",
    "#   - Данные: train_loader, val_loader, test_loader уже созданы.\n",
    "#   - Список имён классов: label_names.\n",
    "#   - Устройство: device (cpu/cuda).\n",
    "# Использование:\n",
    "#   - Передаём модель и \"строитель\" оптимизатора (optimizer_builder),\n",
    "#     чтобы легко менять оптимизатор между запусками.\n",
    "# ============================================================\n",
    "\n",
    "from copy import deepcopy\n",
    "from typing import Callable, Dict, Any\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "set_seed(42)\n",
    "@torch.no_grad()\n",
    "def collect_preds_targets(model: nn.Module, loader: DataLoader):\n",
    "    model.eval()\n",
    "    all_true, all_pred, all_prob = [], [], []\n",
    "    for images, targets in loader:\n",
    "        images  = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits  = model(images)\n",
    "        probs   = torch.softmax(logits, dim=1)\n",
    "        preds   = probs.argmax(dim=1)\n",
    "        all_true.append(targets.cpu())\n",
    "        all_pred.append(preds.cpu())\n",
    "        all_prob.append(probs.cpu())\n",
    "    y_true = torch.cat(all_true).numpy()\n",
    "    y_pred = torch.cat(all_pred).numpy()\n",
    "    y_prob = torch.cat(all_prob).numpy()  # [N, num_classes]\n",
    "    return y_true, y_pred, y_prob\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Оценка модели: усреднённый loss по элементам и глобальная accuracy (sklearn).\n",
    "# ------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model: nn.Module, loader: DataLoader, criterion: nn.Module):\n",
    "    model.eval()\n",
    "    total_loss, total_items = 0.0, 0\n",
    "    all_true, all_pred = [], []\n",
    "    for images, targets in loader:\n",
    "        images  = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits  = model(images)\n",
    "        loss    = criterion(logits, targets)\n",
    "\n",
    "        bs = targets.size(0)\n",
    "        total_loss  += loss.item() * bs\n",
    "        total_items += bs\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_true.append(targets.cpu())\n",
    "        all_pred.append(preds.cpu())\n",
    "\n",
    "    y_true = torch.cat(all_true).numpy()\n",
    "    y_pred = torch.cat(all_pred).numpy()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return {\"loss\": total_loss / max(total_items, 1), \"acc\": acc}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Обучение за одну эпоху: глобальный loss/accuracy по всем элементам (sklearn).\n",
    "# ------------------------------------------------------------\n",
    "def train_one_epoch(model: nn.Module, loader: DataLoader, optimizer: torch.optim.Optimizer, criterion: nn.Module):\n",
    "    model.train()\n",
    "    total_loss, total_items = 0.0, 0\n",
    "    all_true, all_pred = [], []\n",
    "    for images, targets in loader:\n",
    "        images  = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(images)\n",
    "        loss   = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = targets.size(0)\n",
    "        total_loss  += loss.item() * bs\n",
    "        total_items += bs\n",
    "        all_true.append(targets.cpu())\n",
    "        all_pred.append(logits.detach().argmax(dim=1).cpu())\n",
    "\n",
    "    y_true = torch.cat(all_true).numpy()\n",
    "    y_pred = torch.cat(all_pred).numpy()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return {\"loss\": total_loss / max(total_items, 1), \"acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef0a8b-2246-4bfc-9c1a-4b3b18641e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "#  цикл эпох: train → val, журнал history.\n",
    "# ------------------------------------------------------------\n",
    "from copy import deepcopy\n",
    "from typing import Callable, Dict, Any\n",
    "set_seed(42)\n",
    "def run_experiment(\n",
    "    model: nn.Module,\n",
    "    optimizer_builder: Callable[[Any], torch.optim.Optimizer],\n",
    "    *,\n",
    "    num_epochs: int = cfg.epochs,\n",
    "    print_every: int = 1,\n",
    "    criterion: nn.Module | None = None,\n",
    ") -> Dict[str, Any]:\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optimizer_builder(model.parameters())\n",
    "\n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_metrics = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_metrics   = evaluate_model(model, val_loader,   criterion)\n",
    "\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"train_loss\"].append(train_metrics[\"loss\"])\n",
    "        history[\"train_acc\"].append(train_metrics[\"acc\"])\n",
    "        history[\"val_loss\"].append(val_metrics[\"loss\"])\n",
    "        history[\"val_acc\"].append(val_metrics[\"acc\"])\n",
    "\n",
    "        if (epoch % print_every) == 0:\n",
    "            print(f\"[epoch {epoch:02d}] \"\n",
    "                  f\"train: loss={train_metrics['loss']:.4f}, acc={train_metrics['acc']:.3f} | \"\n",
    "                  f\"val:   loss={val_metrics['loss']:.4f}, acc={val_metrics['acc']:.3f}\")\n",
    "\n",
    "    return {\"history\": history}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd17215-f511-413b-b71e-61729d75ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Обучение модели с оптимизатором SGD.\n",
    "# ============================================================\n",
    "set_seed(42)\n",
    "model_sgd = SimpleCNN(num_classes=len(label_names)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Строитель оптимизатора: позволяет переиспользовать общий цикл\n",
    "def build_sgd(params):\n",
    "    return torch.optim.SGD(params, lr=cfg.lr)  # базовый SGD без momentum\n",
    "\n",
    "exp_sgd = run_experiment(\n",
    "    model=model_sgd,\n",
    "    optimizer_builder=build_sgd,\n",
    "    num_epochs=10,\n",
    "    print_every=1,\n",
    "    criterion=criterion,\n",
    ")\n",
    "\n",
    "# Короткая сводка по итогам валидации\n",
    "print(f\"Лучшее val acc: {max(exp_sgd['history']['val_acc']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c47e3-1dc2-4fa2-b047-7c05b4eadc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Визуализация кривых обучения для SGD.\n",
    "# ------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = exp_sgd[\"history\"][\"epoch\"]\n",
    "tr_loss = exp_sgd[\"history\"][\"train_loss\"]; va_loss = exp_sgd[\"history\"][\"val_loss\"]\n",
    "tr_acc  = exp_sgd[\"history\"][\"train_acc\"];  va_acc  = exp_sgd[\"history\"][\"val_acc\"]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs, tr_loss, marker=\"o\", label=\"train loss\")\n",
    "plt.plot(epochs, va_loss, marker=\"o\", label=\"val loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.title(\"SGD: динамика loss\"); plt.grid(True, linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs, tr_acc, marker=\"o\", label=\"train acc\")\n",
    "plt.plot(epochs, va_acc, marker=\"o\", label=\"val acc\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.title(\"SGD: динамика accuracy\"); plt.grid(True, linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bebf40-bd19-4bcb-9d43-095c3743f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Тестовая оценка: accuracy + подробный отчёт по классам.\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true_test, y_pred_test, y_prob_test = collect_preds_targets(model_sgd, test_loader)\n",
    "acc_test = accuracy_score(y_true_test, y_pred_test)\n",
    "print(f\"Accuracy (test, SGD): {acc_test:.3f}\\n\")\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=label_names, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5362a6-c6a4-4249-b8c8-d7d55d5a0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Матрица ошибок и гистограммы precision/recall/F1 по классам.\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "\n",
    "cm = confusion_matrix(y_true_test, y_pred_test, labels=list(range(len(label_names))))\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names).plot(ax=ax, cmap=\"Blues\", values_format=\"d\", colorbar=True)\n",
    "ax.set_title(\"Матрица ошибок — SGD (test)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "prec, rec, f1, support = precision_recall_fscore_support(\n",
    "    y_true_test, y_pred_test, labels=list(range(len(label_names)))\n",
    ")\n",
    "\n",
    "x = np.arange(len(label_names)); w = 0.25\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(x - w, prec, width=w, label=\"precision\")\n",
    "plt.bar(x,       rec, width=w, label=\"recall\")\n",
    "plt.bar(x + w,    f1, width=w, label=\"F1\")\n",
    "plt.xticks(x, label_names); plt.ylim(0, 1)\n",
    "plt.ylabel(\"score\"); plt.title(\"Качество по классам — SGD (test)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d880e49e-2148-4065-a570-6dac8e70d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Saliency map: |∂ logit_true / ∂ input|, показываем как тепловую карту.\n",
    "# ============================================================\n",
    "\n",
    "def saliency_map(model: nn.Module, images: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Возвращает Карту внимания (saliency-карту) для каждого изображения батча:\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    images = images.clone().detach().to(device).requires_grad_(True)  # включаем градиенты по входу\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    logits = model(images)                      # [B, num_classes]\n",
    "    selected = logits.gather(1, labels.view(-1,1)).squeeze(1)  # логит «правильного» класса\n",
    "    selected.backward(torch.ones_like(selected))                \n",
    "\n",
    "    grad = images.grad.detach()                \n",
    "    sal = grad.abs().max(dim=1).values          \n",
    "    B = sal.size(0)\n",
    "    sal = sal.view(B, -1)\n",
    "    sal = (sal - sal.min(dim=1, keepdim=True).values) / (sal.max(dim=1, keepdim=True).values - sal.min(dim=1, keepdim=True).values + 1e-8)\n",
    "    sal = sal.view(B, images.size(2), images.size(3))\n",
    "    return sal.cpu()\n",
    "\n",
    "# берём небольшой батч из валидации\n",
    "images_demo, labels_demo = next(iter(val_loader))\n",
    "images_demo = images_demo[:8]\n",
    "labels_demo = labels_demo[:8]\n",
    "sal_demo = saliency_map(model_sgd, images_demo, labels_demo)  # [B,H,W]\n",
    "\n",
    "# Визуализация: исходное изображение + saliency (как тепловая карта)\n",
    "import matplotlib.pyplot as plt\n",
    "B = images_demo.size(0)\n",
    "cols = 2\n",
    "rows = B\n",
    "plt.figure(figsize=(cols*3, rows*2.2))\n",
    "for i in range(B):\n",
    "    # Исходное\n",
    "    ax = plt.subplot(rows, cols, 2*i+1)\n",
    "    ax.imshow(images_demo[i].permute(1,2,0).numpy(), interpolation=\"none\")\n",
    "    ax.set_title(f\"{label_names[int(labels_demo[i])]}\", fontsize=9); ax.axis(\"off\")\n",
    "\n",
    "    # Saliency\n",
    "    ax = plt.subplot(rows, cols, 2*i+2)\n",
    "    ax.imshow(sal_demo[i].numpy(), cmap=\"inferno\", interpolation=\"none\")\n",
    "    ax.set_title(\"saliency\", fontsize=9); ax.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333c300-c1fc-4646-b19e-1a355cc5201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Модель  и обучение с SGD + momentum.\n",
    "# ------------------------------------------------------------\n",
    "set_seed(42)\n",
    "model_momentum = SimpleCNN(num_classes=len(label_names)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def build_sgd_momentum(params):\n",
    "    return torch.optim.SGD(params, lr=cfg.lr, momentum=0.9)  # nesterov=False (классический momentum)\n",
    "\n",
    "exp_momentum = run_experiment(\n",
    "    model=model_momentum,\n",
    "    optimizer_builder=build_sgd_momentum,\n",
    "    num_epochs=10,\n",
    "    print_every=1,\n",
    "    criterion=criterion,\n",
    ")\n",
    "\n",
    "# Короткая сводка по итогам валидации\n",
    "print(f\"Лучшее val acc: {max(exp_momentum['history']['val_acc']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09ef9d-6f2b-4dcb-bb64-1e50d84a657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Визуализация кривых обучения для SGD+Momentum.\n",
    "# ------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ep = exp_momentum[\"history\"][\"epoch\"]\n",
    "tr_loss = exp_momentum[\"history\"][\"train_loss\"]; va_loss = exp_momentum[\"history\"][\"val_loss\"]\n",
    "tr_acc  = exp_momentum[\"history\"][\"train_acc\"];  va_acc  = exp_momentum[\"history\"][\"val_acc\"]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(ep, tr_loss, marker=\"o\", label=\"train loss\")\n",
    "plt.plot(ep, va_loss, marker=\"o\", label=\"val loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.title(\"SGD+Momentum: динамика loss\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(ep, tr_acc, marker=\"o\", label=\"train acc\")\n",
    "plt.plot(ep, va_acc, marker=\"o\", label=\"val acc\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.title(\"SGD+Momentum: динамика accuracy\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ea873-c3ab-48c2-89cc-6279c54e376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Тестовая оценка (sklearn): accuracy + подробный отчёт по классам.\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_true_m, y_pred_m, y_prob_m = collect_preds_targets(model_momentum, test_loader)\n",
    "acc_test_m = accuracy_score(y_true_m, y_pred_m)\n",
    "print(f\"Accuracy (test, SGD+Momentum): {acc_test_m:.3f}\\n\")\n",
    "print(classification_report(y_true_m, y_pred_m, target_names=label_names, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a294ad1b-122f-4a70-a71d-e053aa92c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Матрица ошибок и гистограммы precision/recall/F1 по классам (sklearn).\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "cm_m = confusion_matrix(y_true_m, y_pred_m, labels=list(range(len(label_names))))\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_m, display_labels=label_names).plot(ax=ax, cmap=\"Blues\", values_format=\"d\", colorbar=True)\n",
    "ax.set_title(\"Матрица ошибок — SGD+Momentum (test)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "prec_m, rec_m, f1_m, sup_m = precision_recall_fscore_support(\n",
    "    y_true_m, y_pred_m, labels=list(range(len(label_names)))\n",
    ")\n",
    "\n",
    "x = np.arange(len(label_names)); w = 0.25\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(x - w, prec_m, width=w, label=\"precision\")\n",
    "plt.bar(x,       rec_m, width=w, label=\"recall\")\n",
    "plt.bar(x + w,    f1_m, width=w, label=\"F1\")\n",
    "plt.xticks(x, label_names); plt.ylim(0, 1)\n",
    "plt.ylabel(\"score\"); plt.title(\"Качество по классам — SGD+Momentum (test)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eea3f9-9f17-4cb6-8bb4-3397689186cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Saliency map: |∂ logit_true / ∂ input|, показываем как тепловую карту.\n",
    "# ============================================================\n",
    "\n",
    "images_demo, labels_demo = next(iter(val_loader))\n",
    "images_demo = images_demo[:8]\n",
    "labels_demo = labels_demo[:8]\n",
    "sal_demo = saliency_map(model_momentum, images_demo, labels_demo)  # [B,H,W]\n",
    "\n",
    "# Визуализация: исходное изображение + saliency (как тепловая карта)\n",
    "import matplotlib.pyplot as plt\n",
    "B = images_demo.size(0)\n",
    "cols = 2\n",
    "rows = B\n",
    "plt.figure(figsize=(cols*3, rows*2.2))\n",
    "for i in range(B):\n",
    "    # Исходное\n",
    "    ax = plt.subplot(rows, cols, 2*i+1)\n",
    "    ax.imshow(images_demo[i].permute(1,2,0).numpy(), interpolation=\"none\")\n",
    "    ax.set_title(f\"{label_names[int(labels_demo[i])]}\", fontsize=9); ax.axis(\"off\")\n",
    "\n",
    "    # Saliency\n",
    "    ax = plt.subplot(rows, cols, 2*i+2)\n",
    "    ax.imshow(sal_demo[i].numpy(), cmap=\"inferno\", interpolation=\"none\")\n",
    "    ax.set_title(\"saliency\", fontsize=9); ax.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410a615-82d0-4c84-804f-6cfa7bc164af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Модель и обучение с Adam.\n",
    "# ------------------------------------------------------------\n",
    "set_seed(42)\n",
    "model_adam = SimpleCNN(num_classes=len(label_names)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def build_adam(params):\n",
    "    return torch.optim.Adam(params, lr=cfg.lr)  # Может не обучаться, придется подбирать экспериментально\n",
    "\n",
    "exp_adam = run_experiment(\n",
    "    model=model_adam,\n",
    "    optimizer_builder=build_adam,\n",
    "    num_epochs=10,\n",
    "    print_every=1,\n",
    "    criterion=criterion,\n",
    ")\n",
    "\n",
    "print(f\"Лучшее val acc: {max(exp_adam['history']['val_acc']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd081e-4bb5-4ea4-96e1-227e0298e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Визуализация кривых обучения для Adam.\n",
    "# ------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ep = exp_adam[\"history\"][\"epoch\"]\n",
    "tr_loss = exp_adam[\"history\"][\"train_loss\"]; va_loss = exp_adam[\"history\"][\"val_loss\"]\n",
    "tr_acc  = exp_adam[\"history\"][\"train_acc\"];  va_acc  = exp_adam[\"history\"][\"val_acc\"]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(ep, tr_loss, marker=\"o\", label=\"train loss\")\n",
    "plt.plot(ep, va_loss, marker=\"o\", label=\"val loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.title(\"Adam: динамика loss\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(ep, tr_acc, marker=\"o\", label=\"train acc\")\n",
    "plt.plot(ep, va_acc, marker=\"o\", label=\"val acc\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.title(\"Adam: динамика accuracy\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ddacb-9643-4b42-b06a-36877a4f1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Тестовая оценка (sklearn): accuracy + подробный отчёт по классам.\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_true_a, y_pred_a, y_prob_a = collect_preds_targets(model_adam, test_loader)\n",
    "acc_test_a = accuracy_score(y_true_a, y_pred_a)\n",
    "print(f\"Accuracy (test, Adam): {acc_test_a:.3f}\\n\")\n",
    "print(classification_report(y_true_a, y_pred_a, target_names=label_names, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a154e-d099-4f1a-ae58-d51515647128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Матрица ошибок и гистограммы precision/recall/F1 по классам (sklearn).\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "cm_a = confusion_matrix(y_true_a, y_pred_a, labels=list(range(len(label_names))))\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_a, display_labels=label_names).plot(ax=ax, cmap=\"Blues\", values_format=\"d\", colorbar=True)\n",
    "ax.set_title(\"Матрица ошибок — Adam (test)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "prec_a, rec_a, f1_a, sup_a = precision_recall_fscore_support(\n",
    "    y_true_a, y_pred_a, labels=list(range(len(label_names)))\n",
    ")\n",
    "\n",
    "x = np.arange(len(label_names)); w = 0.25\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(x - w, prec_a, width=w, label=\"precision\")\n",
    "plt.bar(x,       rec_a, width=w, label=\"recall\")\n",
    "plt.bar(x + w,    f1_a, width=w, label=\"F1\")\n",
    "plt.xticks(x, label_names); plt.ylim(0, 1)\n",
    "plt.ylabel(\"score\"); plt.title(\"Качество по классам — Adam (test)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e4067-d61b-4897-850e-f0856e5b25b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Saliency map: |∂ logit_true / ∂ input|, показываем как тепловую карту.\n",
    "# ============================================================\n",
    "\n",
    "images_demo, labels_demo = next(iter(val_loader))\n",
    "images_demo = images_demo[:8]\n",
    "labels_demo = labels_demo[:8]\n",
    "sal_demo = saliency_map(model_adam, images_demo, labels_demo)  # [B,H,W]\n",
    "\n",
    "# Визуализация: исходное изображение + saliency (как тепловая карта)\n",
    "import matplotlib.pyplot as plt\n",
    "B = images_demo.size(0)\n",
    "cols = 2\n",
    "rows = B\n",
    "plt.figure(figsize=(cols*3, rows*2.2))\n",
    "for i in range(B):\n",
    "    # Исходное\n",
    "    ax = plt.subplot(rows, cols, 2*i+1)\n",
    "    ax.imshow(images_demo[i].permute(1,2,0).numpy(), interpolation=\"none\")\n",
    "    ax.set_title(f\"{label_names[int(labels_demo[i])]}\", fontsize=9); ax.axis(\"off\")\n",
    "\n",
    "    # Saliency\n",
    "    ax = plt.subplot(rows, cols, 2*i+2)\n",
    "    ax.imshow(sal_demo[i].numpy(), cmap=\"inferno\", interpolation=\"none\")\n",
    "    ax.set_title(\"saliency\", fontsize=9); ax.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b2108-ef06-4ef0-ae6d-62c180c62fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Модель (новый экземпляр) и обучение с AdamW.\n",
    "# AdamW = Adam + корректная L2-регуляризация (weight_decay).\n",
    "# ------------------------------------------------------------\n",
    "set_seed(42)\n",
    "model_adamw = SimpleCNN(num_classes=len(label_names)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def build_adamw(params):\n",
    "    return torch.optim.AdamW(params, lr=1e-3, weight_decay=1e-2) \n",
    "\n",
    "exp_adamw = run_experiment(\n",
    "    model=model_adamw,\n",
    "    optimizer_builder=build_adamw,\n",
    "    num_epochs=10,\n",
    "    print_every=1,\n",
    "    criterion=criterion,\n",
    ")\n",
    "print(f\"Лучшее val acc: {max(exp_adamw['history']['val_acc']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba470f-f42a-4349-ade9-74dd7079ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Визуализация кривых обучения для AdamW.\n",
    "# ------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ep = exp_adamw[\"history\"][\"epoch\"]\n",
    "tr_loss = exp_adamw[\"history\"][\"train_loss\"]; va_loss = exp_adamw[\"history\"][\"val_loss\"]\n",
    "tr_acc  = exp_adamw[\"history\"][\"train_acc\"];  va_acc  = exp_adamw[\"history\"][\"val_acc\"]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(ep, tr_loss, marker=\"o\", label=\"train loss\")\n",
    "plt.plot(ep, va_loss, marker=\"o\", label=\"val loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.title(\"AdamW: динамика loss\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(ep, tr_acc, marker=\"o\", label=\"train acc\")\n",
    "plt.plot(ep, va_acc, marker=\"o\", label=\"val acc\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.title(\"AdamW: динамика accuracy\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7b4d1-2f2a-48b8-ae75-5f6f4cf8a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Тестовая оценка (sklearn): accuracy + подробный отчёт по классам.\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_true_w, y_pred_w, y_prob_w = collect_preds_targets(model_adamw, test_loader)\n",
    "acc_test_w = accuracy_score(y_true_w, y_pred_w)\n",
    "print(f\"Accuracy (test, AdamW): {acc_test_w:.3f}\\n\")\n",
    "print(classification_report(y_true_w, y_pred_w, target_names=label_names, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e231f-da5d-43a5-9b84-0d07e1f943c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Матрица ошибок и гистограммы precision/recall/F1 по классам (sklearn).\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "cm_w = confusion_matrix(y_true_w, y_pred_w, labels=list(range(len(label_names))))\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_w, display_labels=label_names).plot(ax=ax, cmap=\"Blues\", values_format=\"d\", colorbar=True)\n",
    "ax.set_title(\"Матрица ошибок — AdamW (test)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "prec_w, rec_w, f1_w, sup_w = precision_recall_fscore_support(\n",
    "    y_true_w, y_pred_w, labels=list(range(len(label_names)))\n",
    ")\n",
    "\n",
    "x = np.arange(len(label_names)); w = 0.25\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(x - w, prec_w, width=w, label=\"precision\")\n",
    "plt.bar(x,       rec_w, width=w, label=\"recall\")\n",
    "plt.bar(x + w,    f1_w, width=w, label=\"F1\")\n",
    "plt.xticks(x, label_names); plt.ylim(0, 1)\n",
    "plt.ylabel(\"score\"); plt.title(\"Качество по классам — AdamW (test)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67ae753-e580-4aaf-aed0-6d3995e53ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Saliency map: |∂ logit_true / ∂ input|, показываем как тепловую карту.\n",
    "# ============================================================\n",
    "\n",
    "images_demo, labels_demo = next(iter(val_loader))\n",
    "images_demo = images_demo[:8]\n",
    "labels_demo = labels_demo[:8]\n",
    "sal_demo = saliency_map(model_adamw, images_demo, labels_demo)  # [B,H,W]\n",
    "\n",
    "# Визуализация: исходное изображение + saliency (как тепловая карта)\n",
    "import matplotlib.pyplot as plt\n",
    "B = images_demo.size(0)\n",
    "cols = 2\n",
    "rows = B\n",
    "plt.figure(figsize=(cols*3, rows*2.2))\n",
    "for i in range(B):\n",
    "    # Исходное\n",
    "    ax = plt.subplot(rows, cols, 2*i+1)\n",
    "    ax.imshow(images_demo[i].permute(1,2,0).numpy(), interpolation=\"none\")\n",
    "    ax.set_title(f\"{label_names[int(labels_demo[i])]}\", fontsize=9); ax.axis(\"off\")\n",
    "\n",
    "    # Saliency\n",
    "    ax = plt.subplot(rows, cols, 2*i+2)\n",
    "    ax.imshow(sal_demo[i].numpy(), cmap=\"inferno\", interpolation=\"none\")\n",
    "    ax.set_title(\"saliency\", fontsize=9); ax.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcdf990-8a64-42e8-8dff-1129706bb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Сравнение динамики обучения для нескольких оптимизаторов.\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _collect_histories() -> list[tuple[str, dict]]:\n",
    "    \"\"\"Собирает пары (название, history) из глобальных переменных, если они существуют.\"\"\"\n",
    "    candidates = [\n",
    "        (\"SGD\",       globals().get(\"exp_sgd\",       {}).get(\"history\")),\n",
    "        (\"Momentum\",  globals().get(\"exp_momentum\",  {}).get(\"history\")),\n",
    "        (\"Adam\",      globals().get(\"exp_adam\",      {}).get(\"history\")),\n",
    "        (\"AdamW\",     globals().get(\"exp_adamw\",     {}).get(\"history\")),\n",
    "    ]\n",
    "    return [(name, hist) for name, hist in candidates if isinstance(hist, dict) and len(hist.get(\"epoch\", [])) > 0]\n",
    "\n",
    "histories = _collect_histories()\n",
    "assert histories, \"Нет историй обучения для сравнения. Убедитесь, что exp_* уже получены.\"\n",
    "\n",
    "# Приводим все серии к общей длине (минимум эпох среди переданных историй),\n",
    "# чтобы кривые были сопоставимы по оси X.\n",
    "min_len = min(len(h[\"epoch\"]) for _, h in histories)\n",
    "\n",
    "# Готовим наборы серий для отрисовки\n",
    "series = []\n",
    "for name, h in histories:\n",
    "    series.append({\n",
    "        \"name\": name,\n",
    "        \"epoch\":     h[\"epoch\"][:min_len],\n",
    "        \"train_loss\":h[\"train_loss\"][:min_len],\n",
    "        \"val_loss\":  h[\"val_loss\"][:min_len],\n",
    "        \"train_acc\": h[\"train_acc\"][:min_len],\n",
    "        \"val_acc\":   h[\"val_acc\"][:min_len],\n",
    "    })\n",
    "\n",
    "# --- Loss ---\n",
    "plt.figure(figsize=(7, 4.2))\n",
    "for s in series:\n",
    "    plt.plot(s[\"epoch\"], s[\"train_loss\"], marker=\"o\", linewidth=1.5, label=f\"{s['name']} | train\")\n",
    "    plt.plot(s[\"epoch\"], s[\"val_loss\"],   marker=\"o\", linewidth=1.5, linestyle=\"--\", label=f\"{s['name']} | val\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.title(\"Сравнение оптимизаторов: loss\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5); plt.legend(ncol=2, fontsize=9)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- Accuracy ---\n",
    "plt.figure(figsize=(7, 4.2))\n",
    "for s in series:\n",
    "    plt.plot(s[\"epoch\"], s[\"train_acc\"], marker=\"o\", linewidth=1.5, label=f\"{s['name']} | train\")\n",
    "    plt.plot(s[\"epoch\"], s[\"val_acc\"],   marker=\"o\", linewidth=1.5, linestyle=\"--\", label=f\"{s['name']} | val\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.title(\"Сравнение оптимизаторов: accuracy\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5); plt.legend(ncol=2, fontsize=9)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49b8a0-f14e-47b1-a8af-455d19860c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Сводная таблица финальных метрик на тесте (sklearn accuracy).\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def _ensure_preds(model_var_name: str, loader, cache_prefix: str):\n",
    "    \"\"\"\n",
    "    Проверяет, есть ли уже y_true_*, y_pred_*; если нет — собирает через collect_preds_targets().\n",
    "    Возвращает (y_true, y_pred).\n",
    "    \"\"\"\n",
    "    y_true_name = f\"y_true_{cache_prefix}\"\n",
    "    y_pred_name = f\"y_pred_{cache_prefix}\"\n",
    "\n",
    "    if y_true_name in globals() and y_pred_name in globals():\n",
    "        return globals()[y_true_name], globals()[y_pred_name]\n",
    "\n",
    "    model_obj = globals().get(model_var_name, None)\n",
    "    assert model_obj is not None, f\"Модель {model_var_name} не найдена. Сначала запустите её обучение.\"\n",
    "    y_true, y_pred, _ = collect_preds_targets(model_obj, loader)\n",
    "    globals()[y_true_name] = y_true\n",
    "    globals()[y_pred_name] = y_pred\n",
    "    return y_true, y_pred\n",
    "\n",
    "rows = []\n",
    "# Описываем, что сравниваем: (метка, имя модели в глобалах, префикс для кэша, история)\n",
    "candidates = [\n",
    "    (\"SGD\",       \"model_sgd\",      \"test\", globals().get(\"exp_sgd\",      {}).get(\"history\")),\n",
    "    (\"Momentum\",  \"model_momentum\", \"m\",    globals().get(\"exp_momentum\", {}).get(\"history\")),\n",
    "    (\"Adam\",      \"model_adam\",     \"a\",    globals().get(\"exp_adam\",     {}).get(\"history\")),\n",
    "    (\"AdamW\",     \"model_adamw\",    \"w\",    globals().get(\"exp_adamw\",    {}).get(\"history\")),\n",
    "]\n",
    "\n",
    "for name, model_glob, cache_pref, hist in candidates:\n",
    "    if model_glob not in globals() or not isinstance(hist, dict):\n",
    "        continue\n",
    "    y_true, y_pred = _ensure_preds(model_glob, test_loader, cache_pref)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    best_val = float(np.max(hist[\"val_acc\"])) if len(hist.get(\"val_acc\", [])) else np.nan\n",
    "    rows.append({\"optimizer\": name, \"test_acc\": acc, \"best_val_acc\": best_val})\n",
    "\n",
    "assert rows, \"Нет данных для таблицы. Убедитесь, что эксперименты запущены.\"\n",
    "df_cmp = pd.DataFrame(rows).sort_values(\"test_acc\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(\n",
    "    df_cmp.style\n",
    "    .set_caption(\"Сводная таблица: test accuracy и лучшая val accuracy\")\n",
    "    .format({\"test_acc\": \"{:.3f}\", \"best_val_acc\": \"{:.3f}\"})\n",
    "    .hide(axis=\"index\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d9e32-e23b-4edf-988c-7ac999f077be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
