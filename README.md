<center><h1>Введение в машинное обучение</h1></center>

## Пререквизиты

- **Программирование на Python.** Уверенное владение основами Python, включая умение писать и понимать код, а также работать с основными библиотеками для численных вычислений и анализа данных, такими как NumPy, Pandas, Seaborn и Matplotlib.
- **Анализ и визуализация данных.** Опыт работы с данными, включающий их сбор, предобработку, визуализацию и анализ с использованием инструментов Python. Понимание методов очистки, нормализации и аугментации данных.
- **Основы статистики и теории вероятностей.** Знание ключевых концепций статистики, таких как вероятностные распределения, математическое ожидание и дисперсия. Опыт работы с вероятностными моделями, включая базовые байесовские методы.
- **Линейная алгебра.** Базовое понимание линейной алгебры, включая операции с матрицами и векторами, а также их применение в машинном обучении, например, при работе с нейросетями.
- 
## Темы лекций и семинаров

### Лекции

1. [**Основные этапы жизненного цикла машинного обучения**](./lectures/1_Жизненный_цикл.pdf). Жизненный цикл машинного обучения, его этапы и важность в построении успешных решений. Рассмотрение ключевых шагов: постановка задачи, сбор и подготовка данных, конструирование признаков, выбор и обучение модели, её тестирование, внедрение и последующий мониторинг. Подчёркивается итеративный характер процесса, где ошибки и новые данные требуют возврата к предыдущим шагам для повышения качества и устойчивости моделей.
2. [**Функции потерь**](./lectures/2_Функции_потерь.pdf). Функции потерь как ключевой элемент обучения моделей машинного обучения. Рассмотрение их роли как меры ошибки и механизма обратной связи, обеспечивающего корректировку параметров. Обзор базовых функций для регрессии (MAE, MSE, RMSE), классификации (NLL, кросс-энтропия, hinge), задач ранжирования и metric learning (Margin Ranking, Triplet Loss), а также распределений (KL-дивергенция). Подчёркивается, что выбор функции потерь зависит от постановки задачи, данных и целей, и универсального решения не существует.

### Семинары

1. [**Жизненный цикл машинного обучения: практическая демонстрация.**](./practice_1/1.ipynb). Разбор базового пайплайна машинного обучения на прикладном примере. Рассмотрены этапы подготовки данных, обучения модели, выбора метрик и анализа результатов. Показана практическая реализация типового ML-эксперимента.
2. [**Функции потерь.**](./practice_2/2.ipynb) Подробное рассмотрение различных функций потерь в задачах регрессии и классификации. Проведена экспериментальная демонстрация работы выбора функции потерь на процесс обучения модели.

## Система оценивания

Оценка за курс формируется следующим образом:
Оценка = 0.5 * Домашняя работа + 0.5 * Экзамен (итоговый проект)

### Домашняя работа

Всего предусмотрено **8** домашних заданий, каждое из которых оценивается в **0.5** балла. Задания охватывают различные аспекты машинного обучения: постановка задач, работа с данными, выбор моделей, обучение и оценка качества.

Все домашние работы должны быть загружены на **GitHub**, и необходимо отправить ссылку на репозиторий в [**Телеграмм**](https://t.me/MiSTe_R).

#### Критерии оценки для домашней работы

- **Отлично (8):** выполненная работа в полном объёме
- **Хорошо (6–7):** выполнено не менее 80%
- **Удовлетворительно (4–5):** выполнено 50%
- **Неудовлетворительно (0–3):** выполнено менее 50%

## Экзамен

Для сдачи экзамена по данному курсу необходимо подготовить учебный исследовательский проект.
Проект должен быть основан на реальных данных, которые можно взять из открытых источников (например, из [HuggingFace Datasets](https://huggingface.co/datasets)).

### Структура экзаменационной презентации
- **Цель работы.** Чёткое описание задачи, которую предстоит решить с использованием методов машинного обучения.
- **Описание исходных данных.** Подробное представление данных, включая источник, структуру и ключевые характеристики.
- **Используемые алгоритмы с обоснованием.** Описание применяемых методов и алгоритмов машинного обучения с объяснением, почему они были выбраны для решения задачи.
- **Как измерялось качество моделей.** Описание метрик, использованных для оценки производительности моделей, и методов анализа результатов.
- **Итоговые результаты.** Представление полученных результатов, выводы по сравнению моделей, а также их интерпретация.

На презентацию выделяется 10 минут (5 минут на доклад и 5 минут на вопросы). Допускается выполнение проекта в парах.
Весь код и презентация проекта должны быть загружены на **GitHub**, оформлены с **README файлом**, и необходимо отправить приглашение на репозиторий [**пользователю**](https://github.com/MiSTeR1995).

Критерии выставления оценок:
- **4 балла** — выполнение домашних заданий
  (8 заданий по 0.5 балла за каждое, округление в пользу студента; для получения максимума необходимо выполнить все 8 заданий).
- **4 балла** — защита итогового проекта.
- **До 2 баллов** — выполнение дополнительных требований к проекту (1 балл за каждое):
  - Использование **двух и более наборов данных** (корпусов) из открытых источников, таких как [Hugging Face Datasets](https://huggingface.co/datasets).
  - Создание **интерактивного приложения** с использованием [Gradio](https://gradio.app/) или [Streamlit](https://streamlit.io/), размещённого на Hugging Face Spaces, которое позволяет вводить данные для модели и получать результаты.
  - Разработка **Telegram-бота**, интегрированного с моделью, для демонстрации её работы в диалоговом формате.
  - Проведение **сравнительного анализа нескольких семейств моделей** (например, классические алгоритмы, ансамбли, нейросети) с обоснованием сильных и слабых сторон.
  - Реализация **метрик и визуализаций качества** «с нуля» (не только использование готовых функций библиотек, но и собственная имплементация с объяснением).
  - Репликация или адаптация **эксперимента из научной статьи** (NeurIPS, ICML, ACL и др.), с разбором отличий и полученных результатов.
